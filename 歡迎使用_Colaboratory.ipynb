{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tsung-Hung/dummy-git/blob/master/%E6%AD%A1%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision \n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "dHW39iCRdUOc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://discuss.pytorch.org/t/f-batch-norm-returns-different-results-in-train-and-eval-mode-given-same-setup/140493\n",
        "https://stackoverflow.com/questions/68478856/pytorch-batchnorm2d-calculation\n",
        "https://www.bing.com/search?q=class+BatchNorm2d+source+code+&qs=n&form=QBRE&msbsrank=6_6__0&sp=-1&pq=class+batchnorm2d+source+&sc=6-25&sk=&cvid=08ABB45423784303AC7BE5FF2B9A5E71&ghsh=0&ghacc=0&ghpl=&ntref=1\n",
        "https://discuss.pytorch.org/t/how-to-use-scripting-with-custom-batchnorm/85375/5"
      ],
      "metadata": {
        "id": "G696TCf4WhDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LayerNorm replace by BatchNorm"
      ],
      "metadata": {
        "id": "gAWZtsX95OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch, sentence_length, embedding_dim = 2, 3, 5\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "origin = layer_norm(embedding)\n",
        "origin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxI4c6cdEtH",
        "outputId": "59c6a6ac-6396-4194-9404-38c9215ea847"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3191, -1.2100,  0.3728,  1.5161, -0.9981],\n",
              "         [ 0.6920, -0.1628, -0.4517, -1.5029,  1.4254],\n",
              "         [-0.8536,  0.2704, -1.2848,  0.3004,  1.5675]],\n",
              "\n",
              "        [[ 1.1463, -0.4023, -0.6082,  1.1860, -1.3219],\n",
              "         [ 0.6311, -1.3177, -0.6910,  1.5370, -0.1594],\n",
              "         [ 0.9259, -0.3042,  1.3389, -1.3899, -0.5705]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm(x):\n",
        "    '''\n",
        "    BatchNorm2d\n",
        "    '''\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim, 1)\n",
        "    layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=False, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm(embedding)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7lBixnFdECe",
        "outputId": "e5a19183-2c75-4f1f-fc70-5c1701a0466c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3191, -1.2100,  0.3728,  1.5161, -0.9981],\n",
              "         [ 0.6920, -0.1628, -0.4517, -1.5029,  1.4254],\n",
              "         [-0.8536,  0.2704, -1.2848,  0.3004,  1.5675]],\n",
              "\n",
              "        [[ 1.1463, -0.4023, -0.6082,  1.1860, -1.3219],\n",
              "         [ 0.6311, -1.3177, -0.6910,  1.5370, -0.1594],\n",
              "         [ 0.9259, -0.3042,  1.3389, -1.3899, -0.5705]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm2(x):\n",
        "    '''\n",
        "    BatchNorm1d\n",
        "    '''\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim)\n",
        "    layer_norm = nn.BatchNorm1d(x.shape[1], track_running_stats=False, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm2(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "sxbtODU3wSmK",
        "outputId": "ccd27abb-c406-4a6d-f7c7-9e6b6bfaaeac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3191, -1.2100,  0.3728,  1.5161, -0.9981],\n",
              "         [ 0.6920, -0.1628, -0.4517, -1.5029,  1.4254],\n",
              "         [-0.8536,  0.2704, -1.2848,  0.3004,  1.5675]],\n",
              "\n",
              "        [[ 1.1463, -0.4023, -0.6082,  1.1860, -1.3219],\n",
              "         [ 0.6311, -1.3177, -0.6910,  1.5370, -0.1594],\n",
              "         [ 0.9259, -0.3042,  1.3389, -1.3899, -0.5705]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm3 = nn.BatchNorm1d(3, track_running_stats=False, affine=True)\n",
        "def loop_layernorm1(x):\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    # layer_norm = nn.BatchNorm1d(sentence_length,momentum=1.0, affine=True, track_running_stats=False)\n",
        "    \n",
        "    split_x = torch.split(x,1,dim=0)\n",
        "    concate_list = []\n",
        "    for small_x in split_x:\n",
        "        small_x = small_x.squeeze().permute(1,0)\n",
        "        small_x = norm3(small_x).permute(1,0)\n",
        "        concate_list.append(small_x)\n",
        "        # print (small_x.shape)\n",
        "    \n",
        "    concate = torch.stack(concate_list)\n",
        "    # print (concate.shape)\n",
        "    return concate\n",
        "\n",
        "\n",
        "test = loop_layernorm1(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "_JnZKe9oAFBb",
        "outputId": "78eb48ad-4bca-4bbf-a4d6-2d967318362f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3191, -1.2100,  0.3728,  1.5161, -0.9981],\n",
              "         [ 0.6920, -0.1628, -0.4517, -1.5029,  1.4254],\n",
              "         [-0.8536,  0.2704, -1.2848,  0.3004,  1.5675]],\n",
              "\n",
              "        [[ 1.1463, -0.4023, -0.6082,  1.1860, -1.3219],\n",
              "         [ 0.6311, -1.3177, -0.6910,  1.5370, -0.1594],\n",
              "         [ 0.9259, -0.3042,  1.3389, -1.3899, -0.5705]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_x = torch.split(embedding,1,dim=0)\n",
        "split_x"
      ],
      "metadata": {
        "id": "gf8Kf9WABKIa",
        "outputId": "af8eb808-fd6a-4ef4-cd66-e8dbbdda4236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.5147, -0.3306,  0.5444,  1.1764, -0.2134],\n",
              "          [ 0.3620, -0.3695, -0.6167, -1.5162,  0.9895],\n",
              "          [-0.3416,  0.6495, -0.7217,  0.6760,  1.7932]]]),\n",
              " tensor([[[-0.1185, -0.8210, -0.9144, -0.1005, -1.2381],\n",
              "          [ 1.0833, -0.4301,  0.0566,  1.7868,  0.4694],\n",
              "          [-0.2575, -0.8897, -0.0453, -1.4478, -1.0266]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm2(nn.Module):\n",
        "  def __init__(self, num_features, eps=1e-6):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.ones(num_features), requires_grad=False)\n",
        "    self.bias = nn.Parameter(torch.zeros(num_features), requires_grad=False)\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    shape = x.shape\n",
        "    mean = x.mean(-1)\n",
        "    std = torch.sqrt(x.var(-1, unbiased=False))\n",
        "    res = torch.stack([((x[i][j] - mean[i][j]).squeeze(0) / (std[i][j].squeeze(0) + self.eps)) for i in range(x.shape[0]) for j in range(x.shape[1])], dim=0)\n",
        "    return res.reshape(shape)\n",
        "\n",
        "layer_norm2 = LayerNorm2(embedding_dim)\n",
        "# Activate module\n",
        "test = layer_norm2(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "O_3YqcTUGfdo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# matmul 4D tensor"
      ],
      "metadata": {
        "id": "vTdfn3dc5qrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(2,2,4,8)\n",
        "a2 = torch.rand(2,2,6,8)\n",
        "\n",
        "result = torch.matmul(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result.shape)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3lhWQSo7GTg",
        "outputId": "9176e2b4-8df0-4474-9cbb-c35d9e18200a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
              "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
              "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
              "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
              "\n",
              "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
              "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
              "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
              "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
              "\n",
              "\n",
              "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
              "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
              "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
              "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
              "\n",
              "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
              "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
              "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
              "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul1(a1,a2):\n",
        "\n",
        "    k = a1.shape[0]*a1.shape[1]    \n",
        "    mul_list = []\n",
        "    for i in range(a1.shape[0]):\n",
        "        for j in range(a1.shape[1]):\n",
        "            \n",
        "            mul = torch.matmul(a1[i,j,:],a2[i,j,:])                \n",
        "            mul_list.append(mul)\n",
        "\n",
        "    combine = torch.stack(mul_list)  \n",
        "    combine = combine.view(a1.shape[0],a1.shape[1],combine.shape[1],combine.shape[2])\n",
        "    \n",
        "    return combine\n",
        "\n",
        "result1 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result1.shape)\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6MV7b85tuj",
        "outputId": "87047ef4-c7e6-4ba9-b77d-079db17c317f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul2(a1, a2):\n",
        "\n",
        "    combine = torch.stack([torch.matmul(a1[i][j], a2[i][j]) for i in range(a1.shape[0]) for j in range(a1.shape[1])], dim=0)        \n",
        "    return combine.reshape(a1.shape[0], a1.shape[1], a1.shape[2], a2.shape[3])\n",
        "\n",
        "result2 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result2.shape)\n",
        "print(result2)\n",
        "print(torch.all(result==result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPGl88v9Kp-",
        "outputId": "01d4985c-c417-46a3-de15-10644c4dd588"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)\n",
        "  a2 = (2,2,6,8)\n",
        "  torch(a2, a1.T)\n",
        "  '''\n",
        "  B1, N1, H1, T1 = a1.shape\n",
        "  B2, N2, T2, H2 = a2.shape\n",
        "  a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "  #print('a1 : ', a1.shape)\n",
        "  a2 = a2.permute(2,0,1,3)\n",
        "  a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "  #print('a2 : ', a2.shape)\n",
        "  result = torch.matmul(a1, a2)\n",
        "  result = torch.stack([result[i*H1:(i+1)*H1 ,i*H2:(i+1)*H2] for i in range(B1*N1)])\n",
        "  result = result.reshape(B1,N1,H1,H2)\n",
        "  return result\n",
        "\n",
        "result3 = new_matmul3(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result3.shape)\n",
        "print(result3)"
      ],
      "metadata": {
        "id": "jxeeKkVQc61G",
        "outputId": "5614360c-7b33-40f4-bd13-646cb4fd69fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3_plus(a1, a2):\n",
        "    '''\n",
        "    a1 = (2,2,4,8)\n",
        "    a2 = (2,2,6,8)\n",
        "    torch(a2, a1.T)\n",
        "    '''\n",
        "    B1, N1, H1, T1 = a1.shape\n",
        "    B2, N2, T2, H2 = a2.shape\n",
        "    #print(H1,T1,T2,H2)\n",
        "    a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "\n",
        "    a2 = a2.permute(2,0,1,3)\n",
        "    a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "\n",
        "    result = torch.matmul(a1, a2)\n",
        "    result = result.reshape(B1*N1, B1*N1, H1, H2).transpose(1,2)\n",
        "    result = result.reshape(B1*N1*B1*N1, H1, H2)\n",
        "\n",
        "    index = torch.arange(0, B1*N1*B1*N1, (B1*N1)+1)\n",
        "    #result = result[index]\n",
        "    #result= torch.index_select(result,0, index)\n",
        "    result = result[0:4,:,:]\n",
        "    print(result.shape)\n",
        "    #result = result.reshape(1, N1, H1, H2)\n",
        "    result = result.unsqueeze(0)\n",
        "    print(result.shape)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "a1 = torch.rand(1,4,150,16)\n",
        "a2 = torch.rand(1,4,10,16)\n",
        "result3_plus = new_matmul3_plus(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result3_plus.shape)\n",
        "print(result3_plus)   "
      ],
      "metadata": {
        "id": "8VMIVfUGT_UI",
        "outputId": "e1e0205c-11dc-4cb2-efc7-9905ff608922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 150, 10])\n",
            "torch.Size([1, 4, 150, 10])\n",
            "Shape :  torch.Size([1, 4, 150, 10])\n",
            "tensor([[[[3.3838, 3.4120, 3.1763,  ..., 2.8965, 3.7930, 4.0286],\n",
            "          [3.3731, 3.8181, 3.4525,  ..., 3.6661, 5.1197, 4.4346],\n",
            "          [3.9121, 3.2665, 3.6328,  ..., 2.9576, 4.6977, 3.8945],\n",
            "          ...,\n",
            "          [2.4998, 3.4385, 3.3605,  ..., 3.1234, 4.2989, 4.4229],\n",
            "          [4.0505, 3.9032, 3.7065,  ..., 3.2579, 4.0980, 4.0834],\n",
            "          [3.5518, 4.2238, 3.7948,  ..., 2.9784, 3.0524, 3.3058]],\n",
            "\n",
            "         [[2.8244, 3.6988, 3.1481,  ..., 2.4031, 3.4871, 3.2455],\n",
            "          [3.7828, 5.2183, 4.0348,  ..., 3.7653, 3.7374, 3.7913],\n",
            "          [3.0486, 3.5487, 3.0653,  ..., 3.7951, 4.5977, 4.5349],\n",
            "          ...,\n",
            "          [3.3623, 3.3315, 4.0794,  ..., 3.6210, 4.2255, 3.8217],\n",
            "          [3.2363, 4.5231, 3.3725,  ..., 3.9814, 4.6853, 5.5462],\n",
            "          [2.9573, 3.0535, 3.6217,  ..., 2.7151, 3.8101, 3.8697]],\n",
            "\n",
            "         [[4.6520, 5.1243, 4.9299,  ..., 4.3121, 4.3224, 4.1277],\n",
            "          [4.5314, 3.9137, 4.0721,  ..., 3.3219, 4.3879, 3.8848],\n",
            "          [4.4545, 5.4088, 5.3276,  ..., 4.8144, 4.0771, 4.5234],\n",
            "          ...,\n",
            "          [4.0760, 4.5238, 4.7220,  ..., 3.6640, 4.7952, 3.9544],\n",
            "          [2.8258, 2.7128, 3.1329,  ..., 2.5548, 3.3370, 2.3810],\n",
            "          [2.1765, 3.0400, 2.0271,  ..., 2.8231, 3.3744, 2.9271]],\n",
            "\n",
            "         [[3.7741, 3.4279, 3.6872,  ..., 3.1434, 4.1828, 4.0046],\n",
            "          [2.7387, 3.7955, 2.9593,  ..., 3.6976, 4.4720, 4.7824],\n",
            "          [3.3091, 3.1652, 3.3114,  ..., 2.0524, 2.5850, 3.1154],\n",
            "          ...,\n",
            "          [3.7979, 4.8942, 3.2474,  ..., 3.8130, 4.1320, 4.1230],\n",
            "          [4.7602, 4.3455, 4.0072,  ..., 3.4750, 4.5492, 4.1290],\n",
            "          [4.7312, 4.8112, 4.3854,  ..., 4.8785, 4.1635, 4.5173]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul4(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  a = torch.ones(a2.shape[0]*a2.shape[1],a2.shape[3])\n",
        "  identity2 = torch.diag_embed(a).reshape(a2.shape[0]*a2.shape[1]*a2.shape[3], a2.shape[3])\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  result = torch.matmul(result, identity2)\n",
        "  return result\n",
        "\n",
        "def new_matmul_final(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  #identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  a = torch.ones(a2.shape[0]*a2.shape[1],a2.shape[3])\n",
        "  #identity2 = torch.diag_embed(a).reshape(a2.shape[0]*a2.shape[1]*a2.shape[3], a2.shape[3]).cuda()\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  #result = torch.matmul(result, identity2)\n",
        "  return result\n",
        "\n",
        "#result4 = new_matmul4(a1,a2.transpose(-2,-1))\n",
        "#print('Shape : ', result4.shape)\n",
        "#print(result4)"
      ],
      "metadata": {
        "id": "nyGqFwAZBMlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "B2, N2, T2, H2 = a2.shape\n",
        "a2 = a2.reshape( B2 * N2* T2, H2)\n",
        "print(a2.shape)\n",
        "one = torch.ones(B2*N2, H2)\n",
        "a2_I = torch.diag_embed(one).permute(1,0,2).reshape(H2, B2*N2*H2)\n",
        "a2_m = torch.matmul(a2, a2_I)\n",
        "a2_m"
      ],
      "metadata": {
        "id": "ViwnKtbDhQ7T",
        "outputId": "cf8a3307-cea3-421b-f392-ddede22cb69f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7210, 0.2294, 0.4558, 0.0930, 0.7210, 0.2294, 0.4558, 0.0930],\n",
              "        [0.2017, 0.0607, 0.4425, 0.3461, 0.2017, 0.0607, 0.4425, 0.3461],\n",
              "        [0.5573, 0.3538, 0.4102, 0.7203, 0.5573, 0.3538, 0.4102, 0.7203],\n",
              "        [0.8404, 0.7805, 0.1481, 0.0404, 0.8404, 0.7805, 0.1481, 0.0404],\n",
              "        [0.7765, 0.7399, 0.3273, 0.6756, 0.7765, 0.7399, 0.3273, 0.6756],\n",
              "        [0.1364, 0.3438, 0.1867, 0.5070, 0.1364, 0.3438, 0.1867, 0.5070]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = torch.ones(B2*N2, H2)\n",
        "a2_I = torch.diag_embed(one).permute(1,0,2).reshape(H2, B2*N2*H2)\n",
        "a2_I"
      ],
      "metadata": {
        "id": "t_owRnwwpIOX",
        "outputId": "20b2002b-226c-496e-c150-04cb54d423a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test = torch.eye(a2.shape[1])\n",
        "one = torch.ones(2,4)\n",
        "a2_I = torch.diag_embed(one)\n",
        "a2_I\n",
        "#test = torch.matmul(a2,test)\n",
        "#test"
      ],
      "metadata": {
        "id": "kg_m5usTg0ws",
        "outputId": "2d934573-366c-48ae-817d-538709aa7572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 0., 0., 0.],\n",
              "         [0., 1., 0., 0.],\n",
              "         [0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1.]],\n",
              "\n",
              "        [[1., 0., 0., 0.],\n",
              "         [0., 1., 0., 0.],\n",
              "         [0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJW7fBfzg0zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(1,4,15000,16).cuda()\n",
        "a2 = torch.rand(1,4,1000,16).cuda()\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdgNaAyEUWd",
        "outputId": "4f5b149a-d0e9-4c2e-9862-48ca95b79bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.4 µs ± 1.06 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul1(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFTNCQiDuIc",
        "outputId": "35fd1f15-a9a0-471f-e22b-16a88a50b9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.99 ms ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul2(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXP7QIijJZm7",
        "outputId": "305ce9d2-1c14-4768-806d-f0682c97d713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.57 ms ± 46.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 200 -r 7 new_matmul3(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "id": "LGnvF8VoJbZk",
        "outputId": "ea2b0be4-b525-4951-e06b-c053cbc694f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 8.39 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "2.01 ms ± 2.06 ms per loop (mean ± std. dev. of 7 runs, 200 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul4(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9SgwXaPJdVB",
        "outputId": "b49941e3-1978-4d23-9b4a-5ecc1f066198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.5 ms ± 7.34 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1_matrix, a2_matrix.transpose(-2,-1))"
      ],
      "metadata": {
        "id": "A8Awqu7OKjac",
        "outputId": "b76d410a-2237-420b-a0d6-ef80b7391395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "746 µs ± 36.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import matrix\n",
        "A = matrix([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]])\n",
        "A2 = A.I\n",
        "B = matrix([[1,3,2],[6,1,2],[3,1,1],[1,4,1],[1,1,2],[3,2,1]])\n",
        "B * A2 * 2"
      ],
      "metadata": {
        "id": "Xr6cUvqHW6Y5",
        "outputId": "3addd240-c324-4ff7-8fb6-59c521b54515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1., 3., 2., 1., 3., 2.],\n",
              "        [6., 1., 2., 6., 1., 2.],\n",
              "        [3., 1., 1., 3., 1., 1.],\n",
              "        [1., 4., 1., 1., 4., 1.],\n",
              "        [1., 1., 2., 1., 1., 2.],\n",
              "        [3., 2., 1., 3., 2., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AB = matrix([[1,3,2,0,0,0],[6,1,2,0,0,0],[3,1,1,0,0,0],[0,0,0,1,4,1],[0,0,0,1,1,2],[0,0,0,3,2,1]])\n",
        "I1 = matrix([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]])\n",
        "I2 = matrix([[1,0,0,1,0,0],[0,1,0,0,1,0],[0,0,1,0,0,1]])\n",
        "res = AB*I1\n",
        "res"
      ],
      "metadata": {
        "id": "5aGhHB5PjWvC",
        "outputId": "511eabb8-f69a-49a8-d686-b6501fdf7257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 3, 2],\n",
              "        [6, 1, 2],\n",
              "        [3, 1, 1],\n",
              "        [1, 4, 1],\n",
              "        [1, 1, 2],\n",
              "        [3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,10,64)\n",
        "#print(x)\n",
        "gamma, color = x[:, 0].unsqueeze(1), x[:, 1:]\n",
        "#print(gamma)\n",
        "#print(color)\n",
        "#print(color.shape)\n",
        "gamma_linear = nn.Linear(64, 1)\n",
        "gamma_base = nn.Parameter(torch.ones((1)), requires_grad=False)\n",
        "gamma = gamma_linear(gamma).squeeze(-1) \n",
        "#print(gamma_base)\n",
        "\n",
        "color_linear = nn.Linear(64, 1)\n",
        "color_base = nn.Parameter(torch.eye((3)), requires_grad=True)\n",
        "color = color_linear(color).squeeze(-1).view(-1, 3, 3) + color_base\n",
        "print(color)"
      ],
      "metadata": {
        "id": "M1mxmqqW6Vmt",
        "outputId": "8c0300af-3cbc-43ee-856a-d93cfb10e179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7081, -0.1413,  0.0535],\n",
            "         [-0.1295,  0.9730, -0.2034],\n",
            "         [ 0.1608,  0.1183,  1.0428]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}