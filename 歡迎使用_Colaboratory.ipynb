{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tsung-Hung/dummy-git/blob/master/%E6%AD%A1%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "dHW39iCRdUOc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LayerNorm replace by BatchNorm"
      ],
      "metadata": {
        "id": "gAWZtsX95OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch, sentence_length, embedding_dim = 10, 3, 5\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "layer_norm(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxI4c6cdEtH",
        "outputId": "815170a0-58cf-4b61-8b51-fd71ab6bdb5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.8599, -1.0732, -0.0081, -0.1825, -0.5962],\n",
              "         [ 0.3421,  0.5905,  1.1613, -0.3421, -1.7518],\n",
              "         [-0.6546, -0.0478, -1.1937,  0.1276,  1.7686]],\n",
              "\n",
              "        [[ 0.9122, -0.5494,  0.2260,  1.0550, -1.6437],\n",
              "         [-1.6339,  1.0804, -0.2343, -0.2377,  1.0255],\n",
              "         [-0.4407, -0.4257, -1.3807,  1.4345,  0.8126]],\n",
              "\n",
              "        [[-0.0100, -0.8006,  1.5021, -1.3110,  0.6194],\n",
              "         [-0.2305,  1.9685, -0.7868, -0.4687, -0.4825],\n",
              "         [-0.6452, -1.2426,  1.4481,  0.8701, -0.4304]],\n",
              "\n",
              "        [[-1.2780,  0.6840,  0.3786,  1.2765, -1.0611],\n",
              "         [ 0.4832, -1.7623,  1.0547, -0.3992,  0.6237],\n",
              "         [ 1.7316, -0.8269,  0.3565, -0.1862, -1.0751]],\n",
              "\n",
              "        [[ 0.5504,  1.0564, -1.7367,  0.5925, -0.4626],\n",
              "         [-1.9730,  0.2944,  0.6897,  0.6613,  0.3277],\n",
              "         [ 1.6474, -0.0156, -1.0331, -1.0202,  0.4214]],\n",
              "\n",
              "        [[-1.2974,  0.2724, -0.5536, -0.1299,  1.7085],\n",
              "         [ 1.2766,  1.0353, -1.0963, -0.1850, -1.0307],\n",
              "         [ 0.7703, -0.6027,  1.1818, -1.6064,  0.2570]],\n",
              "\n",
              "        [[ 1.1086, -0.2335,  0.7138,  0.1916, -1.7805],\n",
              "         [-1.5876,  0.7365, -0.7592,  0.9839,  0.6264],\n",
              "         [-1.4802,  0.2018,  1.1554, -0.7828,  0.9058]],\n",
              "\n",
              "        [[ 0.8736, -1.0368,  1.3581, -1.1468, -0.0482],\n",
              "         [ 0.8823, -1.5980, -0.4745, -0.0109,  1.2011],\n",
              "         [-1.3970,  1.3343, -0.6478,  0.9011, -0.1907]],\n",
              "\n",
              "        [[ 1.3573,  0.0759, -1.6971, -0.2122,  0.4761],\n",
              "         [-1.4935,  0.5591, -0.1263, -0.4388,  1.4995],\n",
              "         [-0.7680,  1.7038, -1.1212,  0.4339, -0.2484]],\n",
              "\n",
              "        [[ 0.3570,  0.1097, -1.3053, -0.7649,  1.6036],\n",
              "         [-1.2336, -0.6594,  0.1787, -0.0208,  1.7352],\n",
              "         [ 1.2455, -0.4846,  0.2030,  0.6817, -1.6456]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm(x):\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim, 1)\n",
        "    print(x.shape)\n",
        "    layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=False, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm(embedding)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7lBixnFdECe",
        "outputId": "675ab598-5916-4cfb-8562-1bb02143ef53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 30, 5, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.8599, -1.0732, -0.0081, -0.1825, -0.5962],\n",
              "         [ 0.3421,  0.5905,  1.1613, -0.3421, -1.7518],\n",
              "         [-0.6546, -0.0478, -1.1937,  0.1276,  1.7686]],\n",
              "\n",
              "        [[ 0.9122, -0.5494,  0.2260,  1.0550, -1.6437],\n",
              "         [-1.6339,  1.0804, -0.2343, -0.2377,  1.0255],\n",
              "         [-0.4407, -0.4257, -1.3807,  1.4345,  0.8126]],\n",
              "\n",
              "        [[-0.0100, -0.8006,  1.5021, -1.3110,  0.6194],\n",
              "         [-0.2305,  1.9685, -0.7868, -0.4687, -0.4825],\n",
              "         [-0.6452, -1.2426,  1.4481,  0.8701, -0.4304]],\n",
              "\n",
              "        [[-1.2780,  0.6840,  0.3786,  1.2765, -1.0611],\n",
              "         [ 0.4832, -1.7623,  1.0547, -0.3992,  0.6237],\n",
              "         [ 1.7316, -0.8269,  0.3565, -0.1862, -1.0751]],\n",
              "\n",
              "        [[ 0.5504,  1.0564, -1.7367,  0.5925, -0.4626],\n",
              "         [-1.9730,  0.2944,  0.6897,  0.6613,  0.3277],\n",
              "         [ 1.6474, -0.0156, -1.0331, -1.0202,  0.4214]],\n",
              "\n",
              "        [[-1.2974,  0.2724, -0.5536, -0.1299,  1.7085],\n",
              "         [ 1.2766,  1.0353, -1.0963, -0.1850, -1.0307],\n",
              "         [ 0.7703, -0.6027,  1.1818, -1.6064,  0.2570]],\n",
              "\n",
              "        [[ 1.1086, -0.2335,  0.7138,  0.1916, -1.7805],\n",
              "         [-1.5876,  0.7365, -0.7592,  0.9839,  0.6264],\n",
              "         [-1.4802,  0.2018,  1.1554, -0.7828,  0.9058]],\n",
              "\n",
              "        [[ 0.8736, -1.0368,  1.3581, -1.1468, -0.0482],\n",
              "         [ 0.8823, -1.5980, -0.4745, -0.0109,  1.2011],\n",
              "         [-1.3970,  1.3343, -0.6478,  0.9011, -0.1907]],\n",
              "\n",
              "        [[ 1.3573,  0.0759, -1.6971, -0.2122,  0.4761],\n",
              "         [-1.4935,  0.5591, -0.1263, -0.4388,  1.4995],\n",
              "         [-0.7680,  1.7038, -1.1212,  0.4339, -0.2484]],\n",
              "\n",
              "        [[ 0.3570,  0.1097, -1.3053, -0.7649,  1.6036],\n",
              "         [-1.2336, -0.6594,  0.1787, -0.0208,  1.7352],\n",
              "         [ 1.2455, -0.4846,  0.2030,  0.6817, -1.6456]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# matmul 4D tensor"
      ],
      "metadata": {
        "id": "vTdfn3dc5qrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(2,2,4,8)\n",
        "a2 = torch.rand(2,2,6,8)\n",
        "\n",
        "result = torch.matmul(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result.shape)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3lhWQSo7GTg",
        "outputId": "503b1d18-0149-458d-c14d-8e913dadcb89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[3.5439, 2.9560, 2.7772, 3.9363, 3.4186, 2.8114],\n",
              "          [2.5087, 2.0192, 2.0113, 2.2172, 2.2267, 1.7332],\n",
              "          [2.9531, 2.4086, 2.1335, 2.9018, 1.9292, 2.6375],\n",
              "          [2.7683, 2.2980, 2.2833, 3.2471, 2.3955, 2.3795]],\n",
              "\n",
              "         [[2.0654, 1.5485, 0.7727, 1.3474, 2.1318, 2.7252],\n",
              "          [1.9204, 2.0794, 0.6779, 1.4825, 1.8152, 2.9874],\n",
              "          [1.6400, 1.8855, 0.6212, 1.6540, 2.2123, 3.4510],\n",
              "          [1.6438, 1.2472, 0.6591, 0.9081, 1.6807, 2.1922]]],\n",
              "\n",
              "\n",
              "        [[[2.2484, 1.9139, 1.1007, 2.1397, 0.4913, 1.5439],\n",
              "          [2.3228, 2.2215, 2.0116, 2.2048, 0.7323, 1.6595],\n",
              "          [2.9425, 2.0890, 1.8181, 2.3023, 0.7836, 1.4039],\n",
              "          [2.0623, 2.3245, 1.7330, 1.9621, 0.7307, 1.2182]],\n",
              "\n",
              "         [[1.7489, 2.5604, 2.1668, 3.0693, 2.6092, 1.6370],\n",
              "          [2.2356, 1.7715, 2.4803, 2.8954, 2.5324, 2.0765],\n",
              "          [2.0889, 2.3783, 2.4830, 2.9700, 2.4808, 2.1869],\n",
              "          [2.3668, 2.0330, 2.7988, 3.1784, 2.8252, 2.2808]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul1(a1,a2):\n",
        "\n",
        "    k = a1.shape[0]*a1.shape[1]    \n",
        "    mul_list = []\n",
        "    for i in range(a1.shape[0]):\n",
        "        for j in range(a1.shape[1]):\n",
        "            \n",
        "            mul = torch.matmul(a1[i,j,:],a2[i,j,:])                \n",
        "            mul_list.append(mul)\n",
        "\n",
        "    combine = torch.stack(mul_list)  \n",
        "    combine = combine.view(a1.shape[0],a1.shape[1],combine.shape[1],combine.shape[2])\n",
        "    \n",
        "    return combine\n",
        "\n",
        "result1 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result1.shape)\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6MV7b85tuj",
        "outputId": "625274bd-bbde-43df-f19b-91594053ed86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[3.5439, 2.9560, 2.7772, 3.9363, 3.4186, 2.8114],\n",
            "          [2.5087, 2.0192, 2.0113, 2.2172, 2.2267, 1.7332],\n",
            "          [2.9531, 2.4086, 2.1335, 2.9018, 1.9292, 2.6375],\n",
            "          [2.7683, 2.2980, 2.2833, 3.2471, 2.3955, 2.3795]],\n",
            "\n",
            "         [[2.0654, 1.5485, 0.7727, 1.3474, 2.1318, 2.7252],\n",
            "          [1.9204, 2.0794, 0.6779, 1.4825, 1.8152, 2.9874],\n",
            "          [1.6400, 1.8855, 0.6212, 1.6540, 2.2123, 3.4510],\n",
            "          [1.6438, 1.2472, 0.6591, 0.9081, 1.6807, 2.1922]]],\n",
            "\n",
            "\n",
            "        [[[2.2484, 1.9139, 1.1007, 2.1397, 0.4913, 1.5439],\n",
            "          [2.3228, 2.2215, 2.0116, 2.2048, 0.7323, 1.6595],\n",
            "          [2.9425, 2.0890, 1.8181, 2.3023, 0.7836, 1.4039],\n",
            "          [2.0623, 2.3245, 1.7330, 1.9621, 0.7307, 1.2182]],\n",
            "\n",
            "         [[1.7489, 2.5604, 2.1668, 3.0693, 2.6092, 1.6370],\n",
            "          [2.2356, 1.7715, 2.4803, 2.8954, 2.5324, 2.0765],\n",
            "          [2.0889, 2.3783, 2.4830, 2.9700, 2.4808, 2.1869],\n",
            "          [2.3668, 2.0330, 2.7988, 3.1784, 2.8252, 2.2808]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul2(a1, a2):\n",
        "\n",
        "    combine = torch.stack([torch.matmul(a1[i][j], a2[i][j]) for i in range(a1.shape[0]) for j in range(a1.shape[1])], dim=0)        \n",
        "    return combine.reshape(a1.shape[0], a1.shape[1], a1.shape[2], a2.shape[3])\n",
        "\n",
        "result2 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result2.shape)\n",
        "print(result2)\n",
        "print(torch.all(result==result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPGl88v9Kp-",
        "outputId": "96b51ee8-34a5-4ec5-b000-6253349e30be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[3.5439, 2.9560, 2.7772, 3.9363, 3.4186, 2.8114],\n",
            "          [2.5087, 2.0192, 2.0113, 2.2172, 2.2267, 1.7332],\n",
            "          [2.9531, 2.4086, 2.1335, 2.9018, 1.9292, 2.6375],\n",
            "          [2.7683, 2.2980, 2.2833, 3.2471, 2.3955, 2.3795]],\n",
            "\n",
            "         [[2.0654, 1.5485, 0.7727, 1.3474, 2.1318, 2.7252],\n",
            "          [1.9204, 2.0794, 0.6779, 1.4825, 1.8152, 2.9874],\n",
            "          [1.6400, 1.8855, 0.6212, 1.6540, 2.2123, 3.4510],\n",
            "          [1.6438, 1.2472, 0.6591, 0.9081, 1.6807, 2.1922]]],\n",
            "\n",
            "\n",
            "        [[[2.2484, 1.9139, 1.1007, 2.1397, 0.4913, 1.5439],\n",
            "          [2.3228, 2.2215, 2.0116, 2.2048, 0.7323, 1.6595],\n",
            "          [2.9425, 2.0890, 1.8181, 2.3023, 0.7836, 1.4039],\n",
            "          [2.0623, 2.3245, 1.7330, 1.9621, 0.7307, 1.2182]],\n",
            "\n",
            "         [[1.7489, 2.5604, 2.1668, 3.0693, 2.6092, 1.6370],\n",
            "          [2.2356, 1.7715, 2.4803, 2.8954, 2.5324, 2.0765],\n",
            "          [2.0889, 2.3783, 2.4830, 2.9700, 2.4808, 2.1869],\n",
            "          [2.3668, 2.0330, 2.7988, 3.1784, 2.8252, 2.2808]]]])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3(a1, a2):\n",
        "  '''  \n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8) \n",
        "  torch(a2, a1.T)\n",
        "  '''\n",
        "  B1, N1, H1, T1 = a1.shape \n",
        "  B2, N2, H2, T2 = a2.shape \n",
        "  a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "  #print('a1 : ', a1.shape)\n",
        "  #a2 = a2.transpose(-2,-1)\n",
        "  a2 = a2.permute(2,0,1,3)\n",
        "  a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "  #print('a2 : ', a2.shape)\n",
        "  result = torch.matmul(a1, a2) \n",
        "  result = torch.stack([result[i*H1:(i+1)*H1 ,i*H2:(i+1)*H2] for i in range(B1*N1)])\n",
        "  result = result.reshape(B1,N1,H1,H2)\n",
        "  return result\n",
        "\n",
        "result3 = new_matmul3(a1, a2)\n",
        "print('Shape : ', result3.shape)\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKgq9fkk6WTx",
        "outputId": "a6096356-71e1-4f76-e57b-2dde66527f30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([1, 4, 15000, 100])\n",
            "tensor([[[[4.1306, 4.1551, 2.8209,  ..., 2.6060, 3.3173, 3.6580],\n",
            "          [6.1360, 6.2356, 3.8443,  ..., 4.3643, 5.3529, 6.4149],\n",
            "          [5.7874, 4.8149, 3.3059,  ..., 3.8239, 4.6116, 5.6743],\n",
            "          ...,\n",
            "          [4.2056, 4.1895, 3.1463,  ..., 3.3322, 3.7732, 3.9175],\n",
            "          [3.9175, 4.0749, 3.3967,  ..., 3.0140, 3.3787, 4.5128],\n",
            "          [4.8084, 3.9714, 2.4514,  ..., 3.3708, 4.1949, 4.6743]],\n",
            "\n",
            "         [[3.3599, 3.2117, 3.7189,  ..., 4.0706, 4.4173, 4.6591],\n",
            "          [3.7905, 3.2209, 4.2085,  ..., 4.3113, 5.3437, 4.5953],\n",
            "          [2.5402, 2.6899, 2.5743,  ..., 3.1548, 3.6519, 3.4797],\n",
            "          ...,\n",
            "          [3.3800, 3.5784, 4.9551,  ..., 4.0804, 5.1566, 4.5895],\n",
            "          [3.6987, 3.1677, 3.1631,  ..., 4.3601, 4.8928, 4.5060],\n",
            "          [4.1681, 4.5183, 5.3103,  ..., 4.6569, 6.5011, 5.2103]],\n",
            "\n",
            "         [[5.1613, 5.0629, 4.3831,  ..., 3.2147, 5.3007, 4.8530],\n",
            "          [5.0414, 4.9240, 4.2724,  ..., 3.6605, 5.5004, 4.0971],\n",
            "          [3.4228, 3.2841, 3.1108,  ..., 2.4832, 4.0256, 2.9801],\n",
            "          ...,\n",
            "          [5.9109, 4.4980, 4.5473,  ..., 3.5514, 5.0536, 4.3781],\n",
            "          [5.1119, 4.4895, 4.3383,  ..., 3.3950, 5.5477, 3.8741],\n",
            "          [4.7511, 4.9987, 3.9176,  ..., 3.4050, 5.5669, 4.5774]],\n",
            "\n",
            "         [[4.4064, 3.5811, 5.6028,  ..., 4.2296, 4.9755, 3.0564],\n",
            "          [5.3734, 4.5245, 5.9274,  ..., 4.0364, 4.5343, 3.7722],\n",
            "          [3.4763, 2.5539, 3.5253,  ..., 2.7878, 3.3653, 2.0332],\n",
            "          ...,\n",
            "          [2.4651, 2.4606, 2.7141,  ..., 1.7054, 2.4941, 1.9382],\n",
            "          [3.9099, 3.9334, 4.4091,  ..., 3.5170, 4.2844, 3.0034],\n",
            "          [3.9133, 3.4562, 5.4283,  ..., 3.7835, 4.1113, 3.2543]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul4(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  #identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  #result = torch.matmul(result, identity)\n",
        "  return result\n",
        "\n",
        "result4 = new_matmul4(a1,a2.transpose(-2,-1))\n",
        "print('Shape : ', result4.shape)\n",
        "print(result4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyGqFwAZBMlV",
        "outputId": "0fdb3dee-f0ce-4400-98db-007de686e337"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([60000, 4000])\n",
            "tensor([[3.5483, 4.6493, 4.3385,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [3.5493, 5.0386, 3.7879,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [4.0197, 4.8545, 3.7965,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 4.8666, 3.8366, 4.2866],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 3.7308, 3.0926, 3.4936],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 2.6934, 2.1872, 1.7510]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(1,4,15000,16).cuda()\n",
        "a2 = torch.rand(1,4,1000,16).cuda()\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdgNaAyEUWd",
        "outputId": "cc41a5d0-bacc-4d8e-afc3-2b25897e55ea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.5 µs ± 2.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul1(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFTNCQiDuIc",
        "outputId": "ca1406be-5703-42a3-b177-fba6b334daa5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 20.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "3.11 ms ± 1.2 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul2(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXP7QIijJZm7",
        "outputId": "65c5ee2c-15b8-487f-b886-fc7bc6cabeef"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.55 ms ± 68.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 200 -r 7 new_matmul3(a1, a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGnvF8VoJbZk",
        "outputId": "edca9e1d-1cf1-4e6d-f5f0-da5ec39619b9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.83 ms ± 1.94 ms per loop (mean ± std. dev. of 7 runs, 200 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul4(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9SgwXaPJdVB",
        "outputId": "427d2c67-a070-4160-dc46-677af8b4b6b3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 8.23 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "6.62 ms ± 2.32 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8Awqu7OKjac"
      },
      "execution_count": 28,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}