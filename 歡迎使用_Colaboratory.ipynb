{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tsung-Hung/dummy-git/blob/master/%E6%AD%A1%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision \n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "dHW39iCRdUOc"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LayerNorm replace by BatchNorm"
      ],
      "metadata": {
        "id": "gAWZtsX95OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://discuss.pytorch.org/t/f-batch-norm-returns-different-results-in-train-and-eval-mode-given-same-setup/140493\n",
        "#https://stackoverflow.com/questions/68478856/pytorch-batchnorm2d-calculation\n",
        "#https://www.bing.com/search?q=class+BatchNorm2d+source+code+&qs=n&form=QBRE&msbsrank=6_6__0&sp=-1&pq=class+batchnorm2d+source+&sc=6-25&sk=&cvid=08ABB45423784303AC7BE5FF2B9A5E71&ghsh=0&ghacc=0&ghpl=&ntref=1\n",
        "#https://discuss.pytorch.org/t/how-to-use-scripting-with-custom-batchnorm/85375/5"
      ],
      "metadata": {
        "id": "MTstGu4Yb92z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch, sentence_length, embedding_dim = 2, 3, 5\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "print(embedding)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "origin = layer_norm(embedding)\n",
        "print(origin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxI4c6cdEtH",
        "outputId": "d3ab1596-c0aa-47c5-8f19-82a5d00978ca"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.9641, -0.3264, -0.5704, -0.3200, -1.7319],\n",
            "         [-1.0646, -0.6391, -0.4975, -1.2980, -0.5398],\n",
            "         [-0.9724, -0.2570, -0.1610,  1.8681,  2.5809]],\n",
            "\n",
            "        [[ 1.2818,  0.8586,  0.8603, -0.6301,  0.1373],\n",
            "         [ 0.5544, -0.6314,  0.2906, -2.2502, -0.0423],\n",
            "         [ 0.8799,  0.1243, -1.8196,  0.9262, -0.7537]]])\n",
            "tensor([[[ 1.5874,  0.0822, -0.2023,  0.0897, -1.5570],\n",
            "         [-0.8098,  0.5320,  0.9785, -1.5457,  0.8450],\n",
            "         [-1.1604, -0.6364, -0.5661,  0.9204,  1.4425]],\n",
            "\n",
            "        [[ 1.1558,  0.5289,  0.5314, -1.6765, -0.5397],\n",
            "         [ 0.9710, -0.2158,  0.7070, -1.8360,  0.3738],\n",
            "         [ 0.9665,  0.2424, -1.6206,  1.0108, -0.5991]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm(x):\n",
        "    '''\n",
        "    BatchNorm2d\n",
        "    '''\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim, 1)\n",
        "    layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=True, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "def Layer_norm2(x):\n",
        "    '''\n",
        "    BatchNorm1d\n",
        "    '''\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim)\n",
        "    layer_norm = nn.BatchNorm1d(x.shape[1], track_running_stats=False, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm(embedding)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7lBixnFdECe",
        "outputId": "f7872e6b-6f8f-4f03-ef64-86bb3b94a6d1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3465, -1.1429, -1.0091,  1.5830,  0.2225],\n",
              "         [-1.0241, -1.1517,  0.9735,  1.2919, -0.0896],\n",
              "         [ 0.1474, -1.4635, -0.5604,  0.3211,  1.5554]],\n",
              "\n",
              "        [[ 0.1451,  0.7724,  0.2184, -1.9261,  0.7903],\n",
              "         [ 1.1391,  0.4523, -1.2866, -1.1000,  0.7952],\n",
              "         [ 0.6111,  1.0796, -0.1115, -1.8388,  0.2597]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch, sentence_length, embedding_dim = embedding.shape\n",
        "x = embedding.reshape(1, batch*sentence_length, embedding_dim, 1)\n",
        "layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=True, affine=True)\n",
        "output = layer_norm(x)\n",
        "output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "layer_norm.running_mean "
      ],
      "metadata": {
        "id": "dJ3XztqW7uBF",
        "outputId": "649dbfde-7cda-48d5-d350-0ed9e8273fe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0072, -0.0715, -0.0038, -0.0122, -0.0371, -0.0597])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm3(x):\n",
        "    '''\n",
        "    BatchNorm1d\n",
        "    '''\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim)\n",
        "    layer_norm = nn.BatchNorm1d(x.shape[1], track_running_stats=True, affine=True)\n",
        "    #print(layer_norm.weight)\n",
        "    #print(layer_norm.bias)\n",
        "    #print(layer_norm.running_mean)\n",
        "    # Set the running statistics to constant\n",
        "    layer_norm.running_mean.fill_(0)\n",
        "    layer_norm.running_var.fill_(1) \n",
        "\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm3(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "li4zC9yjh4vE",
        "outputId": "a2dbc96a-dff8-42ea-a66f-4e7677910b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3430, -1.5758,  0.3096,  1.5147,  0.0946],\n",
              "         [-1.1580,  1.4034, -0.3166, -0.8549,  0.9261],\n",
              "         [-1.3159, -1.0623,  1.1146,  0.4094,  0.8543]],\n",
              "\n",
              "        [[ 0.6805, -0.5048,  0.2777,  1.2054, -1.6589],\n",
              "         [-1.3882,  1.2785, -0.7990,  0.8942,  0.0144],\n",
              "         [-0.0273, -0.7379, -1.3817,  1.4205,  0.7264]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm3 = nn.BatchNorm1d(3, track_running_stats=False, affine=True)\n",
        "def loop_layernorm1(x):\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    # layer_norm = nn.BatchNorm1d(sentence_length,momentum=1.0, affine=True, track_running_stats=False)\n",
        "    \n",
        "    split_x = torch.split(x,1,dim=0)\n",
        "    concate_list = []\n",
        "    for small_x in split_x:\n",
        "        small_x = small_x.squeeze().permute(1,0)\n",
        "        small_x = norm3(small_x).permute(1,0)\n",
        "        concate_list.append(small_x)\n",
        "        # print (small_x.shape)\n",
        "    \n",
        "    concate = torch.stack(concate_list)\n",
        "    # print (concate.shape)\n",
        "    return concate\n",
        "\n",
        "\n",
        "test = loop_layernorm1(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "_JnZKe9oAFBb",
        "outputId": "9f1d5824-7c2e-42f2-a27c-79d597b5c88b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6652, -0.7223,  1.6224, -0.4840, -1.0813],\n",
              "         [ 0.2661,  1.4295,  0.0388, -1.6979, -0.0365],\n",
              "         [-1.5133,  0.0102,  1.6431, -0.0839, -0.0561]],\n",
              "\n",
              "        [[-1.6453,  1.1871,  0.2770,  0.7192, -0.5380],\n",
              "         [-1.2470,  1.5584,  0.3359, -0.9127,  0.2655],\n",
              "         [ 1.4374, -1.0207,  0.8625, -1.0459, -0.2332]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm2(nn.Module):\n",
        "  def __init__(self, num_features, eps=1e-6):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.ones(num_features), requires_grad=False)\n",
        "    self.bias = nn.Parameter(torch.zeros(num_features), requires_grad=False)\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    shape = x.shape\n",
        "    mean = x.mean(-1)\n",
        "    std = torch.sqrt(x.var(-1, unbiased=False))\n",
        "    res = torch.stack([((x[i][j] - mean[i][j]).squeeze(0) / (std[i][j].squeeze(0) + self.eps)) for i in range(x.shape[0]) for j in range(x.shape[1])], dim=0)\n",
        "    return res.reshape(shape)\n",
        "\n",
        "layer_norm2 = LayerNorm2(embedding_dim)\n",
        "# Activate module\n",
        "test = layer_norm2(embedding)\n",
        "test"
      ],
      "metadata": {
        "id": "O_3YqcTUGfdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the SimpleNet model\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(10, track_running_stats=True, affine=True, momentum=1)\n",
        "    \n",
        "    def Layer_norm1(self, x):\n",
        "        batch, sentence_length, embedding_dim = x.shape\n",
        "        x = x.reshape(1, batch*sentence_length, embedding_dim)\n",
        "        # layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=False, affine=True)\n",
        "        output = self.bn1(x)\n",
        "        output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "        return output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Layer_norm1(x) #input(1,10,64)\n",
        "        x = x[0,0,0]\n",
        "        return x\n",
        "\n",
        "# Generate a simulated dataset\n",
        "inputs = torch.rand(3, 10, 64)\n",
        "labels = torch.randint(low=0, high=10, size=(3,))\n",
        "inputs = torch.Tensor(inputs)\n",
        "labels = torch.Tensor(labels).long()\n",
        "train_dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
        "\n",
        "# Create a DataLoader to load and batch the data\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "net = SimpleNet()\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    print(\"1. Running mean:\", net.bn1.running_mean)\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        print(\"2. Running mean:\", net.bn1.running_mean)\n",
        "    print('Epoch [{}/50], Loss: {:.4f}'.format(epoch+1, running_loss / len(train_loader)))\n",
        "    print(\"3. Running mean:\", net.bn1.running_mean)\n",
        "    print(\"===========================\")"
      ],
      "metadata": {
        "id": "f3pHeecFjwv7",
        "outputId": "714d2ae6-2132-4b5d-94f4-fd521dba0db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Running mean: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "2. Running mean: tensor([0.4859, 0.5081, 0.5124, 0.4705, 0.4992, 0.5370, 0.4727, 0.5215, 0.4754,\n",
            "        0.5214])\n",
            "2. Running mean: tensor([0.5307, 0.4298, 0.4670, 0.4764, 0.4707, 0.5168, 0.5147, 0.5776, 0.5070,\n",
            "        0.4452])\n",
            "2. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "Epoch [1/50], Loss: 2.5307\n",
            "3. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "===========================\n",
            "1. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "2. Running mean: tensor([0.4859, 0.5081, 0.5124, 0.4705, 0.4992, 0.5370, 0.4727, 0.5215, 0.4754,\n",
            "        0.5214])\n",
            "2. Running mean: tensor([0.5307, 0.4298, 0.4670, 0.4764, 0.4707, 0.5168, 0.5147, 0.5776, 0.5070,\n",
            "        0.4452])\n",
            "2. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "Epoch [2/50], Loss: 2.5125\n",
            "3. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "===========================\n",
            "1. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "2. Running mean: tensor([0.4859, 0.5081, 0.5124, 0.4705, 0.4992, 0.5370, 0.4727, 0.5215, 0.4754,\n",
            "        0.5214])\n",
            "2. Running mean: tensor([0.5307, 0.4298, 0.4670, 0.4764, 0.4707, 0.5168, 0.5147, 0.5776, 0.5070,\n",
            "        0.4452])\n",
            "2. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "Epoch [3/50], Loss: 2.4807\n",
            "3. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "===========================\n",
            "1. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "2. Running mean: tensor([0.4859, 0.5081, 0.5124, 0.4705, 0.4992, 0.5370, 0.4727, 0.5215, 0.4754,\n",
            "        0.5214])\n",
            "2. Running mean: tensor([0.5307, 0.4298, 0.4670, 0.4764, 0.4707, 0.5168, 0.5147, 0.5776, 0.5070,\n",
            "        0.4452])\n",
            "2. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "Epoch [4/50], Loss: 2.4389\n",
            "3. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "===========================\n",
            "1. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "2. Running mean: tensor([0.4859, 0.5081, 0.5124, 0.4705, 0.4992, 0.5370, 0.4727, 0.5215, 0.4754,\n",
            "        0.5214])\n",
            "2. Running mean: tensor([0.5307, 0.4298, 0.4670, 0.4764, 0.4707, 0.5168, 0.5147, 0.5776, 0.5070,\n",
            "        0.4452])\n",
            "2. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "Epoch [5/50], Loss: 2.3899\n",
            "3. Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "===========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.bn1.weight)\n",
        "print(net.bn1.bias)\n",
        "print(net.bn1.running_mean)\n",
        "print(net.bn1.running_var)"
      ],
      "metadata": {
        "id": "T_YRm4MxifrD",
        "outputId": "70c56e94-edd5-4ecd-b63c-6f75fdc0baef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([1.0887, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0785, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000], requires_grad=True)\n",
            "tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "tensor([0.0992, 0.0833, 0.0768, 0.0835, 0.0836, 0.0877, 0.0653, 0.0674, 0.0726,\n",
            "        0.0870])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_bn_training(m):\n",
        "    if isinstance(m, nn.BatchNorm1d):\n",
        "        m.train()\n",
        "\n",
        "#test_sample = torch.randn(1, 10, 64)\n",
        "#print(test_sample)\n",
        "net.eval()\n",
        "print(\"After Running mean:\", net.bn1.running_mean)\n",
        "print(net.bn1.training)\n",
        "\n",
        "net.apply(set_bn_training)\n",
        "output = net(test_sample)\n",
        "print(\"Before Running mean:\", net.bn1.running_mean)\n",
        "print(net.bn1.training)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "tjflaLEv28hp",
        "outputId": "4d2868de-453d-4cbd-e4d5-7ac8a94ca731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Running mean: tensor([0.4553, 0.5498, 0.5141, 0.5797, 0.4574, 0.4905, 0.4929, 0.5331, 0.4744,\n",
            "        0.4797])\n",
            "False\n",
            "Before Running mean: tensor([-0.1496, -0.0035, -0.0163, -0.2303,  0.1592,  0.0254,  0.0513, -0.1963,\n",
            "         0.0449,  0.0202])\n",
            "True\n",
            "tensor(1.6269, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(test_sample, dim=2)"
      ],
      "metadata": {
        "id": "0Q4r_phZJSlk",
        "outputId": "2ea544d1-56b0-4770-ba38-976fd86f18d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1496, -0.0035, -0.0163, -0.2303,  0.1592,  0.0254,  0.0513, -0.1963,\n",
              "          0.0449,  0.0202]])"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dzn4JZ5MJEW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet_ln(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleNet_ln, self).__init__()\n",
        "        self.ln1 = nn.LayerNorm(100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(0,1)\n",
        "        x = self.ln1(x)\n",
        "        x = x.transpose(0,1)\n",
        "        return x\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "net_ln = SimpleNet_ln()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(3):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        outputs = net_ln(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print('Epoch [{}/50], Loss: {:.4f}'.format(epoch+1, running_loss / len(train_loader)))"
      ],
      "metadata": {
        "id": "fnCynvKXPvOd",
        "outputId": "b598eaed-29a2-4673-e6af-bdf6b64a1df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 3.9652\n",
            "Epoch [2/50], Loss: 3.9620\n",
            "Epoch [3/50], Loss: 3.9658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# matmul 4D tensor"
      ],
      "metadata": {
        "id": "vTdfn3dc5qrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(2,2,4,8)\n",
        "a2 = torch.rand(2,2,6,8)\n",
        "\n",
        "result = torch.matmul(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result.shape)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3lhWQSo7GTg",
        "outputId": "9176e2b4-8df0-4474-9cbb-c35d9e18200a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
              "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
              "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
              "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
              "\n",
              "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
              "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
              "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
              "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
              "\n",
              "\n",
              "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
              "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
              "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
              "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
              "\n",
              "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
              "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
              "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
              "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul1(a1,a2):\n",
        "\n",
        "    k = a1.shape[0]*a1.shape[1]    \n",
        "    mul_list = []\n",
        "    for i in range(a1.shape[0]):\n",
        "        for j in range(a1.shape[1]):\n",
        "            \n",
        "            mul = torch.matmul(a1[i,j,:],a2[i,j,:])                \n",
        "            mul_list.append(mul)\n",
        "\n",
        "    combine = torch.stack(mul_list)  \n",
        "    combine = combine.view(a1.shape[0],a1.shape[1],combine.shape[1],combine.shape[2])\n",
        "    \n",
        "    return combine\n",
        "\n",
        "result1 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result1.shape)\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6MV7b85tuj",
        "outputId": "87047ef4-c7e6-4ba9-b77d-079db17c317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul2(a1, a2):\n",
        "\n",
        "    combine = torch.stack([torch.matmul(a1[i][j], a2[i][j]) for i in range(a1.shape[0]) for j in range(a1.shape[1])], dim=0)        \n",
        "    return combine.reshape(a1.shape[0], a1.shape[1], a1.shape[2], a2.shape[3])\n",
        "\n",
        "result2 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result2.shape)\n",
        "print(result2)\n",
        "print(torch.all(result==result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPGl88v9Kp-",
        "outputId": "01d4985c-c417-46a3-de15-10644c4dd588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)\n",
        "  a2 = (2,2,6,8)\n",
        "  torch(a2, a1.T)\n",
        "  '''\n",
        "  B1, N1, H1, T1 = a1.shape\n",
        "  B2, N2, T2, H2 = a2.shape\n",
        "  a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "  #print('a1 : ', a1.shape)\n",
        "  a2 = a2.permute(2,0,1,3)\n",
        "  a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "  #print('a2 : ', a2.shape)\n",
        "  result = torch.matmul(a1, a2)\n",
        "  result = torch.stack([result[i*H1:(i+1)*H1 ,i*H2:(i+1)*H2] for i in range(B1*N1)])\n",
        "  result = result.reshape(B1,N1,H1,H2)\n",
        "  return result\n",
        "\n",
        "result3 = new_matmul3(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result3.shape)\n",
        "print(result3)"
      ],
      "metadata": {
        "id": "jxeeKkVQc61G",
        "outputId": "5614360c-7b33-40f4-bd13-646cb4fd69fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.7529, 1.8048, 3.4391, 3.1496, 2.6274, 3.4769],\n",
            "          [2.4426, 2.0310, 2.9492, 2.6178, 2.0630, 3.0072],\n",
            "          [2.5750, 1.7425, 2.7397, 2.7792, 2.1718, 3.1972],\n",
            "          [1.6580, 1.1785, 2.3369, 1.8366, 1.7175, 2.1643]],\n",
            "\n",
            "         [[1.8686, 2.8051, 1.5285, 2.3255, 2.7303, 1.7538],\n",
            "          [1.8524, 3.0672, 2.7623, 2.5586, 2.9062, 1.7388],\n",
            "          [1.6032, 2.7890, 2.5647, 2.1229, 2.5603, 1.6270],\n",
            "          [2.3407, 3.4430, 3.3401, 2.8424, 3.5280, 1.9627]]],\n",
            "\n",
            "\n",
            "        [[[1.7584, 1.6373, 1.7781, 2.0835, 2.0114, 2.3218],\n",
            "          [2.0874, 1.6023, 2.1677, 1.5689, 1.9413, 2.7391],\n",
            "          [1.9117, 1.8505, 1.7674, 1.7359, 1.6690, 2.8128],\n",
            "          [0.9375, 1.0843, 1.4811, 0.9806, 0.9975, 1.1700]],\n",
            "\n",
            "         [[2.1752, 3.0235, 2.3582, 1.6890, 2.5907, 2.0623],\n",
            "          [2.1033, 2.5483, 1.6289, 1.6029, 1.9231, 1.4339],\n",
            "          [2.8346, 3.0774, 2.4985, 1.7280, 2.7036, 2.2743],\n",
            "          [2.0064, 3.0427, 2.5664, 1.8976, 2.3499, 2.1540]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3_plus(a1, a2):\n",
        "    '''\n",
        "    a1 = (2,2,4,8)\n",
        "    a2 = (2,2,6,8)\n",
        "    torch(a2, a1.T)\n",
        "    '''\n",
        "    B1, N1, H1, T1 = a1.shape\n",
        "    B2, N2, T2, H2 = a2.shape\n",
        "    #print(H1,T1,T2,H2)\n",
        "    a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "\n",
        "    a2 = a2.permute(2,0,1,3)\n",
        "    a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "\n",
        "    result = torch.matmul(a1, a2)\n",
        "    result = result.reshape(B1*N1, B1*N1, H1, H2).transpose(1,2)\n",
        "    result = result.reshape(B1*N1*B1*N1, H1, H2)\n",
        "\n",
        "    index = torch.arange(0, B1*N1*B1*N1, (B1*N1)+1)\n",
        "    #result = result[index]\n",
        "    #result= torch.index_select(result,0, index)\n",
        "    result = result[0:4,:,:]\n",
        "    print(result.shape)\n",
        "    #result = result.reshape(1, N1, H1, H2)\n",
        "    result = result.unsqueeze(0)\n",
        "    print(result.shape)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "a1 = torch.rand(1,4,150,16)\n",
        "a2 = torch.rand(1,4,10,16)\n",
        "result3_plus = new_matmul3_plus(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result3_plus.shape)\n",
        "print(result3_plus)   "
      ],
      "metadata": {
        "id": "8VMIVfUGT_UI",
        "outputId": "e1e0205c-11dc-4cb2-efc7-9905ff608922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 150, 10])\n",
            "torch.Size([1, 4, 150, 10])\n",
            "Shape :  torch.Size([1, 4, 150, 10])\n",
            "tensor([[[[3.3838, 3.4120, 3.1763,  ..., 2.8965, 3.7930, 4.0286],\n",
            "          [3.3731, 3.8181, 3.4525,  ..., 3.6661, 5.1197, 4.4346],\n",
            "          [3.9121, 3.2665, 3.6328,  ..., 2.9576, 4.6977, 3.8945],\n",
            "          ...,\n",
            "          [2.4998, 3.4385, 3.3605,  ..., 3.1234, 4.2989, 4.4229],\n",
            "          [4.0505, 3.9032, 3.7065,  ..., 3.2579, 4.0980, 4.0834],\n",
            "          [3.5518, 4.2238, 3.7948,  ..., 2.9784, 3.0524, 3.3058]],\n",
            "\n",
            "         [[2.8244, 3.6988, 3.1481,  ..., 2.4031, 3.4871, 3.2455],\n",
            "          [3.7828, 5.2183, 4.0348,  ..., 3.7653, 3.7374, 3.7913],\n",
            "          [3.0486, 3.5487, 3.0653,  ..., 3.7951, 4.5977, 4.5349],\n",
            "          ...,\n",
            "          [3.3623, 3.3315, 4.0794,  ..., 3.6210, 4.2255, 3.8217],\n",
            "          [3.2363, 4.5231, 3.3725,  ..., 3.9814, 4.6853, 5.5462],\n",
            "          [2.9573, 3.0535, 3.6217,  ..., 2.7151, 3.8101, 3.8697]],\n",
            "\n",
            "         [[4.6520, 5.1243, 4.9299,  ..., 4.3121, 4.3224, 4.1277],\n",
            "          [4.5314, 3.9137, 4.0721,  ..., 3.3219, 4.3879, 3.8848],\n",
            "          [4.4545, 5.4088, 5.3276,  ..., 4.8144, 4.0771, 4.5234],\n",
            "          ...,\n",
            "          [4.0760, 4.5238, 4.7220,  ..., 3.6640, 4.7952, 3.9544],\n",
            "          [2.8258, 2.7128, 3.1329,  ..., 2.5548, 3.3370, 2.3810],\n",
            "          [2.1765, 3.0400, 2.0271,  ..., 2.8231, 3.3744, 2.9271]],\n",
            "\n",
            "         [[3.7741, 3.4279, 3.6872,  ..., 3.1434, 4.1828, 4.0046],\n",
            "          [2.7387, 3.7955, 2.9593,  ..., 3.6976, 4.4720, 4.7824],\n",
            "          [3.3091, 3.1652, 3.3114,  ..., 2.0524, 2.5850, 3.1154],\n",
            "          ...,\n",
            "          [3.7979, 4.8942, 3.2474,  ..., 3.8130, 4.1320, 4.1230],\n",
            "          [4.7602, 4.3455, 4.0072,  ..., 3.4750, 4.5492, 4.1290],\n",
            "          [4.7312, 4.8112, 4.3854,  ..., 4.8785, 4.1635, 4.5173]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul4(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  a = torch.ones(a2.shape[0]*a2.shape[1],a2.shape[3])\n",
        "  identity2 = torch.diag_embed(a).reshape(a2.shape[0]*a2.shape[1]*a2.shape[3], a2.shape[3])\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  result = torch.matmul(result, identity2)\n",
        "  return result\n",
        "\n",
        "def new_matmul_final(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  #identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  a = torch.ones(a2.shape[0]*a2.shape[1],a2.shape[3])\n",
        "  #identity2 = torch.diag_embed(a).reshape(a2.shape[0]*a2.shape[1]*a2.shape[3], a2.shape[3]).cuda()\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  #result = torch.matmul(result, identity2)\n",
        "  return result\n",
        "\n",
        "#result4 = new_matmul4(a1,a2.transpose(-2,-1))\n",
        "#print('Shape : ', result4.shape)\n",
        "#print(result4)"
      ],
      "metadata": {
        "id": "nyGqFwAZBMlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "B2, N2, T2, H2 = a2.shape\n",
        "a2 = a2.reshape( B2 * N2* T2, H2)\n",
        "print(a2.shape)\n",
        "one = torch.ones(B2*N2, H2)\n",
        "a2_I = torch.diag_embed(one).permute(1,0,2).reshape(H2, B2*N2*H2)\n",
        "a2_m = torch.matmul(a2, a2_I)\n",
        "a2_m"
      ],
      "metadata": {
        "id": "ViwnKtbDhQ7T",
        "outputId": "cf8a3307-cea3-421b-f392-ddede22cb69f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7210, 0.2294, 0.4558, 0.0930, 0.7210, 0.2294, 0.4558, 0.0930],\n",
              "        [0.2017, 0.0607, 0.4425, 0.3461, 0.2017, 0.0607, 0.4425, 0.3461],\n",
              "        [0.5573, 0.3538, 0.4102, 0.7203, 0.5573, 0.3538, 0.4102, 0.7203],\n",
              "        [0.8404, 0.7805, 0.1481, 0.0404, 0.8404, 0.7805, 0.1481, 0.0404],\n",
              "        [0.7765, 0.7399, 0.3273, 0.6756, 0.7765, 0.7399, 0.3273, 0.6756],\n",
              "        [0.1364, 0.3438, 0.1867, 0.5070, 0.1364, 0.3438, 0.1867, 0.5070]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = torch.ones(B2*N2, H2)\n",
        "a2_I = torch.diag_embed(one).permute(1,0,2).reshape(H2, B2*N2*H2)\n",
        "a2_I"
      ],
      "metadata": {
        "id": "t_owRnwwpIOX",
        "outputId": "20b2002b-226c-496e-c150-04cb54d423a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test = torch.eye(a2.shape[1])\n",
        "one = torch.ones(2,4)\n",
        "a2_I = torch.diag_embed(one)\n",
        "a2_I\n",
        "#test = torch.matmul(a2,test)\n",
        "#test"
      ],
      "metadata": {
        "id": "kg_m5usTg0ws",
        "outputId": "2d934573-366c-48ae-817d-538709aa7572",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 0., 0., 0.],\n",
              "         [0., 1., 0., 0.],\n",
              "         [0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1.]],\n",
              "\n",
              "        [[1., 0., 0., 0.],\n",
              "         [0., 1., 0., 0.],\n",
              "         [0., 0., 1., 0.],\n",
              "         [0., 0., 0., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJW7fBfzg0zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(1,4,15000,16).cuda()\n",
        "a2 = torch.rand(1,4,1000,16).cuda()\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdgNaAyEUWd",
        "outputId": "4f5b149a-d0e9-4c2e-9862-48ca95b79bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.4 µs ± 1.06 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul1(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFTNCQiDuIc",
        "outputId": "35fd1f15-a9a0-471f-e22b-16a88a50b9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.99 ms ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul2(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXP7QIijJZm7",
        "outputId": "305ce9d2-1c14-4768-806d-f0682c97d713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.57 ms ± 46.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 200 -r 7 new_matmul3(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "id": "LGnvF8VoJbZk",
        "outputId": "ea2b0be4-b525-4951-e06b-c053cbc694f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 8.39 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "2.01 ms ± 2.06 ms per loop (mean ± std. dev. of 7 runs, 200 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul4(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9SgwXaPJdVB",
        "outputId": "b49941e3-1978-4d23-9b4a-5ecc1f066198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.5 ms ± 7.34 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1_matrix, a2_matrix.transpose(-2,-1))"
      ],
      "metadata": {
        "id": "A8Awqu7OKjac",
        "outputId": "b76d410a-2237-420b-a0d6-ef80b7391395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "746 µs ± 36.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import matrix\n",
        "A = matrix([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]])\n",
        "A2 = A.I\n",
        "B = matrix([[1,3,2],[6,1,2],[3,1,1],[1,4,1],[1,1,2],[3,2,1]])\n",
        "B * A2 * 2"
      ],
      "metadata": {
        "id": "Xr6cUvqHW6Y5",
        "outputId": "3addd240-c324-4ff7-8fb6-59c521b54515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1., 3., 2., 1., 3., 2.],\n",
              "        [6., 1., 2., 6., 1., 2.],\n",
              "        [3., 1., 1., 3., 1., 1.],\n",
              "        [1., 4., 1., 1., 4., 1.],\n",
              "        [1., 1., 2., 1., 1., 2.],\n",
              "        [3., 2., 1., 3., 2., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AB = matrix([[1,3,2,0,0,0],[6,1,2,0,0,0],[3,1,1,0,0,0],[0,0,0,1,4,1],[0,0,0,1,1,2],[0,0,0,3,2,1]])\n",
        "I1 = matrix([[1,0,0],[0,1,0],[0,0,1],[1,0,0],[0,1,0],[0,0,1]])\n",
        "I2 = matrix([[1,0,0,1,0,0],[0,1,0,0,1,0],[0,0,1,0,0,1]])\n",
        "res = AB*I1\n",
        "res"
      ],
      "metadata": {
        "id": "5aGhHB5PjWvC",
        "outputId": "511eabb8-f69a-49a8-d686-b6501fdf7257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 3, 2],\n",
              "        [6, 1, 2],\n",
              "        [3, 1, 1],\n",
              "        [1, 4, 1],\n",
              "        [1, 1, 2],\n",
              "        [3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,10,64)\n",
        "#print(x)\n",
        "gamma, color = x[:, 0].unsqueeze(1), x[:, 1:]\n",
        "#print(gamma)\n",
        "#print(color)\n",
        "#print(color.shape)\n",
        "gamma_linear = nn.Linear(64, 1)\n",
        "gamma_base = nn.Parameter(torch.ones((1)), requires_grad=False)\n",
        "gamma = gamma_linear(gamma).squeeze(-1) \n",
        "#print(gamma_base)\n",
        "\n",
        "color_linear = nn.Linear(64, 1)\n",
        "color_base = nn.Parameter(torch.eye((3)), requires_grad=True)\n",
        "color = color_linear(color).squeeze(-1).view(-1, 3, 3) + color_base\n",
        "print(color)"
      ],
      "metadata": {
        "id": "M1mxmqqW6Vmt",
        "outputId": "8c0300af-3cbc-43ee-856a-d93cfb10e179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7081, -0.1413,  0.0535],\n",
            "         [-0.1295,  0.9730, -0.2034],\n",
            "         [ 0.1608,  0.1183,  1.0428]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}