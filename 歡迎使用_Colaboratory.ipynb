{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tsung-Hung/dummy-git/blob/master/%E6%AD%A1%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "dHW39iCRdUOc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LayerNorm replace by BatchNorm"
      ],
      "metadata": {
        "id": "gAWZtsX95OMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch, sentence_length, embedding_dim = 10, 3, 5\n",
        "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
        "layer_norm = nn.LayerNorm(embedding_dim)\n",
        "# Activate module\n",
        "layer_norm(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehxI4c6cdEtH",
        "outputId": "516ce049-e7ee-4156-b152-eb7dee38816b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.7308,  0.3394, -0.3598,  1.2118,  0.5395],\n",
              "         [-1.6366, -0.0361,  1.0493, -0.4040,  1.0275],\n",
              "         [ 1.1531,  1.0474, -0.2123, -0.4690, -1.5192]],\n",
              "\n",
              "        [[-1.1769,  0.8899, -0.7252, -0.4385,  1.4507],\n",
              "         [-1.1468,  0.9449, -0.9675, -0.1808,  1.3502],\n",
              "         [-0.4503,  0.3332, -1.3766, -0.1684,  1.6621]],\n",
              "\n",
              "        [[-0.4306, -0.6724, -0.4838,  1.9912, -0.4045],\n",
              "         [ 0.7504,  0.5666, -1.2971, -1.1130,  1.0930],\n",
              "         [ 0.7756, -0.0152,  0.6368, -1.9267,  0.5295]],\n",
              "\n",
              "        [[ 1.1373,  0.5529,  0.7118, -1.1326, -1.2694],\n",
              "         [ 1.2813, -0.2185, -0.9963,  1.0428, -1.1092],\n",
              "         [ 0.1431,  1.7945, -0.5393, -1.1943, -0.2041]],\n",
              "\n",
              "        [[-0.8677, -0.4115,  1.5856,  0.7176, -1.0240],\n",
              "         [ 0.5900,  0.5884,  0.8392, -1.8937, -0.1239],\n",
              "         [-1.2823, -0.2440,  0.0508, -0.3122,  1.7877]],\n",
              "\n",
              "        [[-1.4657, -0.6722,  0.4679,  1.4621,  0.2079],\n",
              "         [ 0.1624,  0.7439,  0.2070, -1.9273,  0.8140],\n",
              "         [-1.3112,  1.0268, -0.3842, -0.6288,  1.2974]],\n",
              "\n",
              "        [[ 0.4540, -0.2502, -1.7131,  0.1814,  1.3279],\n",
              "         [-1.5755,  0.5673,  0.2260,  1.3500, -0.5678],\n",
              "         [-1.0793, -0.1707, -0.9582,  0.6300,  1.5783]],\n",
              "\n",
              "        [[ 0.4591,  0.1039,  1.5155, -1.4401, -0.6384],\n",
              "         [ 1.7614,  0.1668, -1.1807, -0.6869, -0.0606],\n",
              "         [-1.1538,  0.1287,  1.6817, -0.8799,  0.2233]],\n",
              "\n",
              "        [[-0.0696,  1.9095, -0.8980, -0.6933, -0.2486],\n",
              "         [-0.7758,  0.6101, -1.2953, -0.0697,  1.5308],\n",
              "         [ 0.3819, -0.0494, -1.8276,  0.3037,  1.1914]],\n",
              "\n",
              "        [[-1.7223,  0.7232,  1.1328, -0.3971,  0.2634],\n",
              "         [-1.5645,  0.0875,  1.5425, -0.3182,  0.2527],\n",
              "         [-1.7511,  0.3416,  0.8501, -0.4050,  0.9645]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Layer_norm(x):\n",
        "    batch, sentence_length, embedding_dim = x.shape\n",
        "    x = x.reshape(1, batch*sentence_length, embedding_dim, 1)\n",
        "    print(x.shape)\n",
        "    layer_norm = nn.BatchNorm2d(x.shape[1], track_running_stats=False, affine=True)\n",
        "    output = layer_norm(x)\n",
        "    output = output.reshape(output.shape[1], output.shape[2]).reshape(batch, sentence_length, embedding_dim)\n",
        "    return output\n",
        "\n",
        "test = Layer_norm(embedding)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7lBixnFdECe",
        "outputId": "ebf93418-2d22-413d-8f37-b7d315fe174e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 30, 5, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.7308,  0.3394, -0.3598,  1.2118,  0.5395],\n",
              "         [-1.6366, -0.0361,  1.0493, -0.4040,  1.0275],\n",
              "         [ 1.1531,  1.0474, -0.2123, -0.4690, -1.5192]],\n",
              "\n",
              "        [[-1.1769,  0.8899, -0.7252, -0.4385,  1.4507],\n",
              "         [-1.1468,  0.9449, -0.9675, -0.1808,  1.3502],\n",
              "         [-0.4503,  0.3332, -1.3766, -0.1684,  1.6621]],\n",
              "\n",
              "        [[-0.4306, -0.6724, -0.4838,  1.9912, -0.4045],\n",
              "         [ 0.7504,  0.5666, -1.2971, -1.1130,  1.0930],\n",
              "         [ 0.7756, -0.0152,  0.6368, -1.9267,  0.5295]],\n",
              "\n",
              "        [[ 1.1373,  0.5529,  0.7118, -1.1326, -1.2694],\n",
              "         [ 1.2813, -0.2185, -0.9963,  1.0428, -1.1092],\n",
              "         [ 0.1431,  1.7945, -0.5393, -1.1943, -0.2041]],\n",
              "\n",
              "        [[-0.8677, -0.4115,  1.5856,  0.7176, -1.0240],\n",
              "         [ 0.5900,  0.5884,  0.8392, -1.8937, -0.1239],\n",
              "         [-1.2823, -0.2440,  0.0508, -0.3122,  1.7877]],\n",
              "\n",
              "        [[-1.4657, -0.6722,  0.4679,  1.4621,  0.2079],\n",
              "         [ 0.1624,  0.7439,  0.2070, -1.9273,  0.8140],\n",
              "         [-1.3112,  1.0268, -0.3842, -0.6288,  1.2974]],\n",
              "\n",
              "        [[ 0.4540, -0.2502, -1.7131,  0.1814,  1.3279],\n",
              "         [-1.5755,  0.5673,  0.2260,  1.3500, -0.5678],\n",
              "         [-1.0793, -0.1707, -0.9582,  0.6300,  1.5783]],\n",
              "\n",
              "        [[ 0.4591,  0.1039,  1.5155, -1.4401, -0.6384],\n",
              "         [ 1.7614,  0.1668, -1.1807, -0.6869, -0.0606],\n",
              "         [-1.1538,  0.1287,  1.6817, -0.8799,  0.2233]],\n",
              "\n",
              "        [[-0.0696,  1.9095, -0.8980, -0.6933, -0.2486],\n",
              "         [-0.7758,  0.6101, -1.2953, -0.0697,  1.5308],\n",
              "         [ 0.3819, -0.0494, -1.8276,  0.3037,  1.1914]],\n",
              "\n",
              "        [[-1.7223,  0.7232,  1.1328, -0.3971,  0.2634],\n",
              "         [-1.5645,  0.0875,  1.5425, -0.3182,  0.2527],\n",
              "         [-1.7511,  0.3416,  0.8501, -0.4050,  0.9645]]],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# matmul 4D tensor"
      ],
      "metadata": {
        "id": "vTdfn3dc5qrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(2,2,4,8)\n",
        "a2 = torch.rand(2,2,6,8)\n",
        "\n",
        "result = torch.matmul(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result.shape)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3lhWQSo7GTg",
        "outputId": "fa12ad6d-109e-4429-8115-40b4499a3a02"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[2.8331, 2.7717, 1.8197, 1.9072, 2.6365, 2.8051],\n",
              "          [2.2667, 2.0982, 1.5836, 1.6143, 2.1525, 2.1333],\n",
              "          [1.9435, 1.5990, 1.3051, 1.4194, 1.3878, 1.6595],\n",
              "          [3.0025, 3.4030, 2.4411, 2.8075, 2.6819, 3.4550]],\n",
              "\n",
              "         [[2.9619, 1.8788, 2.7696, 2.1046, 2.2509, 2.8159],\n",
              "          [2.8309, 1.9611, 2.5310, 2.0730, 2.3487, 2.7794],\n",
              "          [2.6447, 2.1122, 2.8377, 2.2849, 2.1042, 3.0009],\n",
              "          [2.5675, 1.7580, 2.6901, 1.9674, 1.8271, 2.6649]]],\n",
              "\n",
              "\n",
              "        [[[2.2773, 2.0813, 3.1141, 2.5992, 2.3233, 4.1886],\n",
              "          [2.2283, 1.8513, 2.5137, 2.5783, 2.4522, 3.2121],\n",
              "          [1.7229, 2.0190, 2.2074, 2.5631, 2.3288, 3.2346],\n",
              "          [2.1737, 2.2139, 2.5276, 2.6603, 2.8101, 3.9480]],\n",
              "\n",
              "         [[1.3014, 3.3570, 2.5664, 3.0435, 2.9156, 1.9071],\n",
              "          [0.8277, 2.2444, 1.6118, 2.1012, 1.9516, 1.4173],\n",
              "          [1.6606, 3.1645, 2.2176, 2.9234, 2.7169, 1.7726],\n",
              "          [1.6313, 2.6954, 1.8212, 2.1942, 2.7870, 1.5543]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul1(a1,a2):\n",
        "\n",
        "    k = a1.shape[0]*a1.shape[1]    \n",
        "    mul_list = []\n",
        "    for i in range(a1.shape[0]):\n",
        "        for j in range(a1.shape[1]):\n",
        "            \n",
        "            mul = torch.matmul(a1[i,j,:],a2[i,j,:])                \n",
        "            mul_list.append(mul)\n",
        "\n",
        "    combine = torch.stack(mul_list)  \n",
        "    combine = combine.view(a1.shape[0],a1.shape[1],combine.shape[1],combine.shape[2])\n",
        "    \n",
        "    return combine\n",
        "\n",
        "result1 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result1.shape)\n",
        "print(result1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6MV7b85tuj",
        "outputId": "1001d3fe-f09f-43c2-e688-08426472fdba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.8331, 2.7717, 1.8197, 1.9072, 2.6365, 2.8051],\n",
            "          [2.2667, 2.0982, 1.5836, 1.6143, 2.1525, 2.1333],\n",
            "          [1.9435, 1.5990, 1.3051, 1.4194, 1.3878, 1.6595],\n",
            "          [3.0025, 3.4030, 2.4411, 2.8075, 2.6819, 3.4550]],\n",
            "\n",
            "         [[2.9619, 1.8788, 2.7696, 2.1046, 2.2509, 2.8159],\n",
            "          [2.8309, 1.9611, 2.5310, 2.0730, 2.3487, 2.7794],\n",
            "          [2.6447, 2.1122, 2.8377, 2.2849, 2.1042, 3.0009],\n",
            "          [2.5675, 1.7580, 2.6901, 1.9674, 1.8271, 2.6649]]],\n",
            "\n",
            "\n",
            "        [[[2.2773, 2.0813, 3.1141, 2.5992, 2.3233, 4.1886],\n",
            "          [2.2283, 1.8513, 2.5137, 2.5783, 2.4522, 3.2121],\n",
            "          [1.7229, 2.0190, 2.2074, 2.5631, 2.3288, 3.2346],\n",
            "          [2.1737, 2.2139, 2.5276, 2.6603, 2.8101, 3.9480]],\n",
            "\n",
            "         [[1.3014, 3.3570, 2.5664, 3.0435, 2.9156, 1.9071],\n",
            "          [0.8277, 2.2444, 1.6118, 2.1012, 1.9516, 1.4173],\n",
            "          [1.6606, 3.1645, 2.2176, 2.9234, 2.7169, 1.7726],\n",
            "          [1.6313, 2.6954, 1.8212, 2.1942, 2.7870, 1.5543]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul2(a1, a2):\n",
        "\n",
        "    combine = torch.stack([torch.matmul(a1[i][j], a2[i][j]) for i in range(a1.shape[0]) for j in range(a1.shape[1])], dim=0)        \n",
        "    return combine.reshape(a1.shape[0], a1.shape[1], a1.shape[2], a2.shape[3])\n",
        "\n",
        "result2 = new_matmul1(a1, a2.transpose(-2,-1))\n",
        "print('Shape : ', result2.shape)\n",
        "print(result2)\n",
        "print(torch.all(result==result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPGl88v9Kp-",
        "outputId": "37a18f49-4c90-4672-cdbc-007b19a9cc4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[2.8331, 2.7717, 1.8197, 1.9072, 2.6365, 2.8051],\n",
            "          [2.2667, 2.0982, 1.5836, 1.6143, 2.1525, 2.1333],\n",
            "          [1.9435, 1.5990, 1.3051, 1.4194, 1.3878, 1.6595],\n",
            "          [3.0025, 3.4030, 2.4411, 2.8075, 2.6819, 3.4550]],\n",
            "\n",
            "         [[2.9619, 1.8788, 2.7696, 2.1046, 2.2509, 2.8159],\n",
            "          [2.8309, 1.9611, 2.5310, 2.0730, 2.3487, 2.7794],\n",
            "          [2.6447, 2.1122, 2.8377, 2.2849, 2.1042, 3.0009],\n",
            "          [2.5675, 1.7580, 2.6901, 1.9674, 1.8271, 2.6649]]],\n",
            "\n",
            "\n",
            "        [[[2.2773, 2.0813, 3.1141, 2.5992, 2.3233, 4.1886],\n",
            "          [2.2283, 1.8513, 2.5137, 2.5783, 2.4522, 3.2121],\n",
            "          [1.7229, 2.0190, 2.2074, 2.5631, 2.3288, 3.2346],\n",
            "          [2.1737, 2.2139, 2.5276, 2.6603, 2.8101, 3.9480]],\n",
            "\n",
            "         [[1.3014, 3.3570, 2.5664, 3.0435, 2.9156, 1.9071],\n",
            "          [0.8277, 2.2444, 1.6118, 2.1012, 1.9516, 1.4173],\n",
            "          [1.6606, 3.1645, 2.2176, 2.9234, 2.7169, 1.7726],\n",
            "          [1.6313, 2.6954, 1.8212, 2.1942, 2.7870, 1.5543]]]])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul3(a1, a2):\n",
        "  '''  \n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8) \n",
        "  torch(a2, a1.T)\n",
        "  '''\n",
        "  B1, N1, H1, T1 = a1.shape \n",
        "  B2, N2, H2, T2 = a2.shape \n",
        "  a1 = a1.reshape(B1 * N1 * H1, T1)\n",
        "  #print('a1 : ', a1.shape)\n",
        "  #a2 = a2.transpose(-2,-1)\n",
        "  a2 = a2.permute(2,0,1,3)\n",
        "  a2 = a2.reshape(T2, B2 * N2 * H2)\n",
        "  #print('a2 : ', a2.shape)\n",
        "  result = torch.matmul(a1, a2) \n",
        "  result = torch.stack([result[i*H1:(i+1)*H1 ,i*H2:(i+1)*H2] for i in range(B1*N1)])\n",
        "  result = result.reshape(B1,N1,H1,H2)\n",
        "  return result\n",
        "\n",
        "result3 = new_matmul3(a1, a2)\n",
        "print('Shape : ', result3.shape)\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKgq9fkk6WTx",
        "outputId": "df90f135-fecf-4545-9446-3e987bd7b269"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape :  torch.Size([2, 2, 4, 6])\n",
            "tensor([[[[1.2786, 2.2635, 1.5673, 2.9284, 2.5029, 2.0595],\n",
            "          [1.2368, 1.8651, 1.6052, 2.8708, 1.6599, 1.8963],\n",
            "          [0.8444, 1.1626, 1.2507, 1.5021, 1.8573, 1.2675],\n",
            "          [1.6751, 3.3484, 2.5815, 3.0021, 3.4962, 3.0348]],\n",
            "\n",
            "         [[1.4606, 2.9339, 2.3312, 2.2957, 3.1507, 2.9177],\n",
            "          [1.3388, 2.5807, 2.2758, 2.7728, 2.9638, 2.9332],\n",
            "          [1.3355, 2.7264, 2.3212, 2.7953, 3.0770, 2.8367],\n",
            "          [1.4994, 3.0412, 1.8695, 2.5386, 2.8736, 2.3483]]],\n",
            "\n",
            "\n",
            "        [[[3.5235, 3.1677, 4.0275, 3.6679, 2.9562, 3.2868],\n",
            "          [2.6863, 2.4466, 3.2364, 3.4208, 2.6917, 2.1805],\n",
            "          [2.7143, 2.2988, 3.6185, 3.2199, 2.6388, 2.2886],\n",
            "          [3.4260, 2.6700, 3.4653, 2.9030, 2.7746, 2.7606]],\n",
            "\n",
            "         [[2.1604, 2.3168, 2.1566, 1.5830, 2.5715, 2.3203],\n",
            "          [1.5586, 1.3905, 1.4417, 1.1030, 1.3046, 1.8581],\n",
            "          [2.5540, 1.7719, 1.9505, 1.4387, 1.9333, 2.3759],\n",
            "          [2.3719, 1.4620, 1.9287, 1.0728, 2.2228, 1.7634]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_matmul4(a1, a2):\n",
        "  '''\n",
        "  a1 = (2,2,4,8)  \n",
        "  a2 = (2,2,6,8)\n",
        "  a1_matrix = (16,32)\n",
        "  a2_matrix = (32,24)\n",
        "  '''\n",
        "  a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "  a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "  #identity = torch.cat([torch.eye(a2.shape[3]) for _ in range(a2.shape[0]*a2.shape[1])]).cuda()\n",
        "  a = torch.ones(a2.shape[0]*a2.shape[1],a2.shape[3])\n",
        "  #identity2 = torch.diag_embed(a).reshape(a2.shape[0]*a2.shape[1]*a2.shape[3], a2.shape[3]).cuda()\n",
        "  result = torch.matmul(a1_matrix, a2_matrix)\n",
        "  #result = torch.matmul(result, identity2)\n",
        "  return result\n",
        "\n",
        "#result4 = new_matmul4(a1,a2.transpose(-2,-1))\n",
        "#print('Shape : ', result4.shape)\n",
        "#print(result4)"
      ],
      "metadata": {
        "id": "nyGqFwAZBMlV"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = torch.rand(1,4,15000,16).cuda()\n",
        "a2 = torch.rand(1,4,1000,16).cuda()\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdgNaAyEUWd",
        "outputId": "ed1bcfb6-c7c6-475c-ce77-39ef96c80833"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.3 µs ± 3.68 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul1(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFTNCQiDuIc",
        "outputId": "282b48cb-16f1-4536-f2a8-11a31b1031b3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 23.61 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "3.24 ms ± 1.28 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul2(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXP7QIijJZm7",
        "outputId": "ed33f418-402f-42c3-f050-264b04471b5b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.58 ms ± 47.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%timeit -n 200 -r 7 new_matmul3(a1, a2)"
      ],
      "metadata": {
        "id": "LGnvF8VoJbZk"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit -n 100 -r 7 new_matmul4(a1, a2.transpose(-2,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9SgwXaPJdVB",
        "outputId": "2589635f-7452-4187-abe8-ba0c626b14f4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 8.82 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "6.67 ms ± 2.35 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1_matrix = torch.block_diag(*[a1[i][j] for i in range(a1.shape[0]) for j in range(a1.shape[1])])\n",
        "a2_matrix = torch.block_diag(*[a2[i][j] for i in range(a2.shape[0]) for j in range(a2.shape[1])])\n",
        "\n",
        "%timeit -n 100 -r 7 torch.matmul(a1_matrix, a2_matrix.transpose(-2,-1))"
      ],
      "metadata": {
        "id": "A8Awqu7OKjac",
        "outputId": "0dd8952c-1974-4191-a8d2-8e643ad92de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.7 µs ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xr6cUvqHW6Y5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}